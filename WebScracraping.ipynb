{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMo6jDpsXiL9QBl+sfgPqlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raylasilva/WebScraping/blob/main/WebScracraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Primeiro impostamos a biblioteca \"Request\" que realiza o mapeamento do protocolo HTTP**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8DnhtZAppNYg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "XBvZwO2xmBB4"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Buscaremos a URL do site que iremos fazer a raspagem, no caso um site de livros online**"
      ],
      "metadata": {
        "id": "PytEKxV5qXR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora usando a biblioteca request, chamaremos a URL como resposta da solicitação.\n",
        "Usando a biblioteca BeautifulSoup entraremos no site para ler o código html do site, após buscaremos as tags necessarios com as informações que estamos querendo, no caso: Imagem, Titulo,Preço, Estrela."
      ],
      "metadata": {
        "id": "2eZQ7AJdq2DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books = []\n",
        "for i in range(1,51):\n",
        "\n",
        "  url = f\"https://books.toscrape.com/catalogue/page-{i}.html\"\n",
        "  response = requests.get(url)\n",
        "  response = response.content\n",
        "  soup = BeautifulSoup(response, 'html.parser')\n",
        "  ol = soup.find('ol')\n",
        "  articles = ol.find_all('article', class_='product_pod')\n",
        "\n",
        "\n",
        "  for article in articles:\n",
        "      image = article.find('img')\n",
        "      title = image.attrs['alt']\n",
        "      star = article.find('p')\n",
        "      star = star['class'][1]\n",
        "      price = article.find('p',class_='price_color').text\n",
        "      price = price[1:]\n",
        "      books.append([image,title, price,star])\n",
        ""
      ],
      "metadata": {
        "id": "y-WCdcLpubn-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(books,columns=['Imagem','Titulo','Preço','Estrela'])"
      ],
      "metadata": {
        "id": "8ytNySyP1KFW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ao final usando a biblioteca Pandas convertemos em tabela, que fica disponievel em 'Arquivos' para Download em csv."
      ],
      "metadata": {
        "id": "zVVFWVuL35_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('books.csv')"
      ],
      "metadata": {
        "id": "AUjM5Qyb1d_Q"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}